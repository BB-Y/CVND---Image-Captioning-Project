{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "0bcc3765-63f2-40be-9122-bed9bb392105"
   },
   "source": [
    "# 计算机视觉纳米学位项目\n",
    "\n",
    "## 实战项目：图像标注\n",
    "\n",
    "---\n",
    "\n",
    "在这个notebook中，你将要使用已被训练的模型为测试数据集中的图像生成标注。\n",
    "\n",
    "我们将对该notebook**进行评分**。\n",
    "\n",
    "你可以通过点击以下链接导航到该notebook：\n",
    "- [Step 1](#step1): 获取测试数据集的数据加载器\n",
    "- [Step 2](#step2): 加载训练模型\n",
    "- [Step 3](#step3): 完成取样器\n",
    "- [Step 4](#step4): 清理标注\n",
    "- [Step 5](#step5): 生成预测！\n",
    "\n",
    "<a id='step1'></a>\n",
    "## Step 1: 获取测试数据集的数据加载器\n",
    "\n",
    "在运行下面的代码单元格之前，请在`transform_test`中定义要用于预处理测试图像的转换。\n",
    "\n",
    "请确保你在此处定义的转换与你在**2_Training.ipynb**中用于预处理训练图像的转换是一致的。例如，如果你对训练图像进行了归一化，则还应对测试图像应用相同的归一化处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "4aad3e19-9328-44a1-8e8b-33011e2edbf7"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/opt/cocoapi/PythonAPI')\n",
    "from pycocotools.coco import COCO\n",
    "from data_loader import get_loader\n",
    "from torchvision import transforms\n",
    "\n",
    "# TODO #1: Define a transform to pre-process the testing images.\n",
    "transform_test = ...\n",
    "\n",
    "#-#-#-# Do NOT modify the code below this line. #-#-#-#\n",
    "\n",
    "# Create the data loader.\n",
    "data_loader = get_loader(transform=transform_test,    \n",
    "                         mode='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "16e720e0-d32c-4b3e-8951-c876bef387f0"
   },
   "source": [
    "在应用预处理之前，运行下面的代码单元格，将示例测试图像可视化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "282694a8-ccfd-425a-a910-3df4e1e337bf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Obtain sample image before and after pre-processing.\n",
    "orig_image, image = next(iter(data_loader))\n",
    "\n",
    "# Visualize sample image, before pre-processing.\n",
    "plt.imshow(np.squeeze(orig_image))\n",
    "plt.title('example image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "9d2a4cc1-e057-4028-9ab1-9c869b64767f"
   },
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: 加载训练模型\n",
    "\n",
    "在下一个代码单元格中，我们定义了一个`device`，你将使用它将PyTorch张量移动到GPU中（如果CUDA可用的话）。在继续下一步之前，请运行此代码单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "efe3aada-4c52-4cc0-8a29-6328980f439d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "2f383d1f-3998-4e3d-aae2-fa2244b9b34b"
   },
   "source": [
    "在运行下面的代码单元格之前，请完成以下任务。\n",
    "\n",
    "### 任务 #1\n",
    "\n",
    "在下一个代码单元格中，你将从之前的notebook（即**2_Training.ipynb**）中加载已被训练的编码器和解码器。要实现此目的，你必须在`models/`文件夹中定义已保存的编码器和解码器文件的名称。例如，如果你使用5个epoch训练了该模型并在每个epoch后保存了权重，则这些名称应为 `encoder-5.pkl`和`decoder-5.pkl`。\n",
    "\n",
    "### 任务＃2\n",
    "\n",
    "插入嵌入尺寸和解码器隐藏层的尺寸，与`decoder_file`中选定的pickle文件相对应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "5f4f253f-9358-4ae3-bdcc-933bd00ffee1"
   },
   "outputs": [],
   "source": [
    "# Watch for any changes in model.py, and re-load it automatically.\n",
    "% load_ext autoreload\n",
    "% autoreload 2\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "\n",
    "# TODO #2: Specify the saved models to load.\n",
    "encoder_file = ... \n",
    "decoder_file = ...\n",
    "\n",
    "# TODO #3: Select appropriate values for the Python variables below.\n",
    "embed_size = ...\n",
    "hidden_size = ...\n",
    "\n",
    "# The size of the vocabulary.\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "\n",
    "# Initialize the encoder and decoder, and set each to inference mode.\n",
    "encoder = EncoderCNN(embed_size)\n",
    "encoder.eval()\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "decoder.eval()\n",
    "\n",
    "# Load the trained weights.\n",
    "encoder.load_state_dict(torch.load(os.path.join('./models', encoder_file)))\n",
    "decoder.load_state_dict(torch.load(os.path.join('./models', decoder_file)))\n",
    "\n",
    "# Move models to GPU if CUDA is available.\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "ee203ff7-0fb1-4f30-adcc-8cb5d68475f4"
   },
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: 完成取样器\n",
    "\n",
    "在执行下一个代码单元格之前，必须要编写**model.py**中的`DecoderRNN`类的`sample` 方法。该方法应接收包含对应于单个图像的嵌入输入特征的PyTorch张量`features`作为输入。\n",
    "\n",
    "作为输出，它应该返回一个Python列表`output`，用于指示预测的语句。 `output[i]`是一个非负整数，用于标识句子中预测的第`i`个标记。你可以通过检查`data_loader.dataset.vocab.word2idx` 或 `data_loader.dataset.vocab.idx2word`来探索整数和标记之间的对应关系。\n",
    "\n",
    "实现`sample`方法后，运行下面的代码单元格。如果单元格返回一个断言错误，请在继续操作之前按照说明修改代码，但请勿修改下面单元格中的代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "02b080a4-8142-408d-b943-6d999d1da0c5"
   },
   "outputs": [],
   "source": [
    "# Move image Pytorch Tensor to GPU if CUDA is available.\n",
    "image = image.to(device)\n",
    "\n",
    "# Obtain the embedded image features.\n",
    "features = encoder(image).unsqueeze(1)\n",
    "\n",
    "# Pass the embedded image features through the model to get a predicted caption.\n",
    "output = decoder.sample(features)\n",
    "print('example output:', output)\n",
    "\n",
    "assert (type(output)==list), \"Output needs to be a Python list\" \n",
    "assert all([type(x)==int for x in output]), \"Output should be a list of integers.\" \n",
    "assert all([x in data_loader.dataset.vocab.idx2word for x in output]), \"Each entry in the output needs to correspond to an integer that indicates a token in the vocabulary.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "451ecee3-2833-4f2a-ae9d-38535eafa545"
   },
   "source": [
    "<a id='step4'></a>\n",
    "## Step 4: 清理标注\n",
    "\n",
    "在下面的代码单元格中，完成`clean_sentence`函数。它应把一个整数列表（对应于**Step 3**中的变量`output`）作为输入并返回相应的预测语句（作为单个Python字符串）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "2a8aed0e-ba8c-4234-bb44-630c6335b16c"
   },
   "outputs": [],
   "source": [
    "# TODO #4: Complete the function.\n",
    "def clean_sentence(output):\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "43ed9137-cac7-46a1-a45a-627f18317d1f"
   },
   "source": [
    "完成上面的`clean_sentence`函数后，运行下面的代码单元格。如果单元格返回一个断言错误，请在继续操作之前按照说明修改代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "e7c749b4-80ba-4a9a-b1f2-ec39e863b371"
   },
   "outputs": [],
   "source": [
    "sentence = clean_sentence(output)\n",
    "print('example sentence:', sentence)\n",
    "\n",
    "assert type(sentence)==str, 'Sentence needs to be a Python string!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "c01ad6be-fcbc-4425-ad43-3c4339be0a9c"
   },
   "source": [
    "<a id='step5'></a>\n",
    "## Step 5: 生成预测！\n",
    "\n",
    "在下面的代码单元格中，我们编写了一个函数(`get_prediction`，你可以使用该函数遍历测试数据集中的图像并输出模型的预测描述。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "3b3435a1-b75f-4ec9-9f93-f8c6df83e526"
   },
   "outputs": [],
   "source": [
    "def get_prediction():\n",
    "    orig_image, image = next(iter(data_loader))\n",
    "    plt.imshow(np.squeeze(orig_image))\n",
    "    plt.title('Sample Image')\n",
    "    plt.show()\n",
    "    image = image.to(device)\n",
    "    features = encoder(image).unsqueeze(1)\n",
    "    output = decoder.sample(features)    \n",
    "    sentence = clean_sentence(output)\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "9f782b28-3bc9-4216-acca-78878656d71a"
   },
   "source": [
    "运行下面的代码单元格，测试此函数的运行方式。如果你愿意的话，可以尝试多次运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "ed14d9af-59e8-4a7d-91f7-7b1186fac1df"
   },
   "outputs": [],
   "source": [
    "get_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "77ef79be-4bc9-48fe-b527-a92c8841bd0d"
   },
   "source": [
    "作为此项目的最后一项任务，你要做的是遍历图像，直到找到四个感兴趣的图像标注对：\n",
    "- 其中，有两个应该包括图像标注对，且该标注对会突出显示模型表现良好的实例。\n",
    "- 另外两个应突出显示图像标注对，且该标注对会突出显示模型效果不佳的实例。\n",
    "\n",
    "使用下面的四个代码单元格来完成此任务。\n",
    "\n",
    "### 该模型表现良好！\n",
    "\n",
    "使用接下来的两个代码单元格来遍历所有标注。如果遇到两张图像有相对准确的标注，请保存该notebook。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "b44d0cbe-9d46-4976-8a52-7cb166310faa"
   },
   "outputs": [],
   "source": [
    "get_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "c8edef16-935f-446f-92c7-9bd75bf76af8"
   },
   "outputs": [],
   "source": [
    "get_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "5ab0ddb1-2ca4-4e7b-8711-8505cb218a44"
   },
   "source": [
    "### 该模型表现不佳......\n",
    "\n",
    "使用接下来的两个代码单元格来遍历所有标注。如果遇到两个图像有相对不准确的标注，请保存该notebook。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "3a327759-fabb-427a-b04b-e30895448a50"
   },
   "outputs": [],
   "source": [
    "get_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "e6fde829-437b-4c84-9d59-e3710b3e6114"
   },
   "outputs": [],
   "source": [
    "get_prediction()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
